# -*- coding: utf-8 -*-
"""Klasifikasi dengan k-NN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LhWd5lAVjN4sXk293iuDz94t8cUa2RPg
"""

import pandas as pd

# 1. dataset <-- titanic.csv
dataset = pd.read_csv('titanic.csv')
print(dataset)

# 2. test_dataset <-- titanic_test.csv
test_data = pd.read_csv('titanic_test.csv')
print(test_data)

# 3. train_data <-- ambil dataset kolom fitur (Age, Fare). Hilangkan baris data yang terdapat
# missing values (catat posisi data yang hilang → pos_missing_train)

# Select features
train_data = dataset[['Age', 'Fare']]

# Find missing values
pos_missing_train = train_data[train_data.isnull().any(axis=1)].index

# Drop missing values
train_data = train_data.dropna()
print(train_data)

# 4. test_data <-- ambil test_dataset kolom fitur (Age, Fare). Hilangkan baris data yang terdapat
# missing values (catat posisi data yang hilang → pos_missing_test).

# Select features
test_data = test_data[['Age', 'Fare']]

# Find missing values
pos_missing_test = test_data[test_data.isnull().any(axis=1)].index

# Drop missing values
test_data = test_data.dropna()
print(test_data)

# 5. train_label <-- ambil train_data kolom kelas (Survived), yang bukan pos_missing_train

train_label = dataset.loc[~dataset.index.isin(pos_missing_train), 'Survived']
print(train_label)

# 6.test_label <-- titanic_testlabel.csv, yang bukan pos_missing_test

test_label = pd.read_csv('titanic_testlabel.csv').loc[~pd.read_csv('titanic_testlabel.csv').index.isin(pos_missing_test), 'Survived']
print(test_label)

# 7. train_data <-- lakukan normalisasi pada train_data dengan Min-Max 0-1 (catat nilai min dan
# max setiap atribut)

from sklearn.preprocessing import MinMaxScaler

# Initialize MinMaxScaler
scaler = MinMaxScaler()

# Fit and transform the data
train_data_scaled = scaler.fit_transform(train_data)

# Convert back to DataFrame
train_data = pd.DataFrame(train_data_scaled, columns=train_data.columns)

# Get min and max values for each attribute
min_values = scaler.data_min_
max_values = scaler.data_max_

print(train_data)
print("Min values:", min_values)
print("Max values:", max_values)

# prompt: test_data <-- lakukan normalisasi pada train_data dengan Min-Max 0-1 (dengan nilai min dan
# max setiap atribut pada Langkah 7)

# Normalize test_data using the min and max values from step 7
test_data_scaled = (test_data - min_values) / (max_values - min_values)

# Convert back to DataFrame
test_data = pd.DataFrame(test_data_scaled, columns=test_data.columns)

print(test_data)

import pandas as pd
from sklearn.neighbors import KNeighborsClassifier

errAll = []

for x in range(1,11):
  print(f"Classification with n = {x}")
  kNN = KNeighborsClassifier(n_neighbors=x, weights='distance')
  kNN.fit(train_data, train_label)
  class_result = kNN.predict(test_data)
  precision_ratio = kNN.score(test_data, test_label)
  error_ratio = 1 - precision_ratio

  class_result_df = pd.DataFrame(class_result, columns=['Predicted'])

  test_label = test_label.reset_index(drop=True)

  comparison_df = pd.concat([test_label, class_result_df], axis=1)

  print(comparison_df)

  print(f"Error Ratio: {error_ratio}\n\n")
  errAll.append(error_ratio)

import numpy as np

errArray = np.array(errAll)
print(errArray)
print(f"The best classification result has error ratio = {errArray.min()} dan n = {errAll.index(errArray.min())+1}")